# 2.2.1 Introduction
This section defines the *Neighbor Selection* protocol, its logic and the different packets exchanged.

In order for the network to work efficiently and for the nodes to be kept up-to-date about the ledger state, nodes exchange information, such as packets and value transactions, with each other. Each node establishes a communication channel with a small subset of nodes (i.e., neighbors) via a process called `peering`. Such a process must be resilient against Eclipse attacks: if all of a node’s neighbors are controlled by an attacker, then the attacker has complete control over the node’s view of the Tangle. Moreover, to prevent/limitate sybil-based attacks, the neighbor selection protocol makes use of a scarce resource dubbed Mana: arbitrary nodes can be created, but it is is difficult to produce high mana nodes.

Throughout this RFC the terms `Node` and `Peer` are used interchangeably to refer to a `Node` device. 

# 2.2.2 Dependencies
The *Neighbor Selection* protocol depends on:

+ Peer discovery: to get a list of the known and verified peers.
+ Mana: to make the neighbor selection based on Mana.

# 2.2.3 Detailed design 
The goal of the neighbor selection is to build a node's neighborhood (to be used by the gossip protocol) while preventing attackers from “tricking” other nodes into becoming neighbors. Neighbors are established when one node sends a peering-request packet to another node, which in turn accepts or rejects the request with a peering-response packet. 

To prevent attacks, the protocol makes the peering-request *verifiably random* such that attackers cannot create nodes to which the target node will send requests. At its core, the neighbor selection protocol uses both a screening process called *Mana rank* and a *score function* that takes into account some randomness dubbed *private* and *public salt*. 
Nodes choose half of their neighbors themselves and let the other half be comprised of neighbors that choose them. The two distinct groups of neighbors are consequently called:
+ Chosen neighbors (outbound). The peers that the node proactively chooses from its list of neighbors.
+ Accepted neighbors (inbound). The peers that choose the node as their neighbor.


## 2.2.3.1 Node identities
As for the *peer discovery* protocol, every node has a cryptographic identity, a key on the Ed25519 elliptic curve. The `blake2b` hash of the public key of the peer serves as its identifier or `node ID`.

## 2.2.3.2 Salt generation

Nodes *shall* have a public and private salt both defined as array bytes of size 20. Nodes *shall* update both their public and private salt at a common fixed time interval `salt_update_interval` (e.g. 3 hours).
The public salt is used for outbound peering requests, while the private salt is used during inbound peering requests.

The public salt must satisfy the following requirements:

1. Future salts must be unguessable: mining node ids to reduce the request score *shall* be prohibitive. This offers protection for the requesting nodes.
2. Salts *shall not* be arbitrarily chosen: if adversaries can choose their salt, they can manufacture malicious requests to any node.

This RFC preposes to set the public salt using hash chains, while private salt can be randomly generated on the fly. New node will create a hash chain, and they make public the last element of their hash chain as their initial salt. Every future salt is the next element of the hash chain. Under this proposal, property 1 holds because cryptograhic hash functions are not reversible. 
Property 2 holds fairly well: an adversary can only choose one element of their hash chain. Indeed, an adversary can pick a number to be their 300th salt, hash it 300 times, and post that as their initial salt. However, an adversary can only do this for one round since hash functions have effectively random outputs. Thus an adversary is limited in their ability to choose their own salt.

## 2.2.3.3 Selection

The maximum number of neighbors depends on the gossip protocol. This RFC proposes to use a size of 8 equally divided into 4 chosen (outbound) and 4 accepted (inbound) neighbors.

The operations involved during neighbor selection are listed in the following:

1.  Get an up-to-date list of verified and known peers from the *Peer Discovery* protocol. 
2.  Use [mana rank](#Mana_rank) to filter the previous list to obtain a list of peers to be potential neighbors.
3.  Use the score function to choose/accept neighbors.

The score between two nodes is measured through the score function *s*, defined by:

s(nodeIdD, nodeID2, salt) = hash(nodeID1) XOR hash(nodeID2 || salt), where: 

+ `nodeID1` and `nodeID2` are the identities of the considered nodes.
+ `salt` is the salt value that can be private or public depending on the peering direction (inbound/outbound).
+ `hash` is the `blake2b` hash function.
+ `XOR` is the bitwise logical *xor* operation.
+ ``||`` is the concatanation operation.

Note that the value used as the score is an unsigned integer derived from the first 4 bytes of the byte array after the `XOR` operation.

In order to connect to new neighbors, each node with ID `ownId` and public salt `ζ` keeps a list of potential neighbors derived via [Mana rank](#Mana_rank) that is sorted by their score `d(ownId, ·, ζ)`. Then, the node sends them peering requests in *ascending order*, containing its own current public salt and a timestamp (its nodeID is already embedded in the [packet](#Packet) containing the peering request). 
The connecting node repeats this process until it has established connections to enough neighbors or it finds closer peers. Those neighbors make up its list of chosen neighbors. This entire process is also illustrated in the following pseudocode:

```
Inputs: 
    k: desired amount of neighbors; 
    C: current list of chosen neighbors; 
    P: list of potential peers;
    ownID: own nodeID 
    pub_salt: own public salt;
    

P_sorted ← sortByScoreAsc(P, ownID, pub_salt)
foreach p ∈ P_sorted do
    peeringRequest ← sendPeeringRequest(p)
    if peeringRequest.accepted then 
        append(C, p)
        if |C| == k/2 then 
            return
```

More specifically, after sending a peering request a node *shall*:
* wait to get a [Peering Response](#Peering_Response) that could be positive or negative. 
    * If positive, add the peer to its chosen neighbor list
    * If negative, filter out the peer from future requests until the next salt update or the end of the list of potential neighbors is reached.
    * If after a timeout no response is received, try again for a fixed `max_peering_attempts` or filter out the peer from future request until the next salt update or the end of the list of potential neighbors is reached.

Similarly to the previous case, in order to accept neighbors, every node with ID ownID *shall* generate a private salt `ζ_private`.

Upon reception of a [Peering Request](#Peering_Request), a peer *shall* make a decision to accept, reject  or discard the request by:
* veryfing that the signature of the [Peering Request](#Peering_Request) packet is valid and discard the packet otherwise;
* checking that the `timestamp` field is fresh (i.e., not older than a given threshold) and discard the packet otherwise;
* checking that the *mana* of the requester peer is within the own [Mana rank](#Mana_rank) and send back a *negative* [Peering Response](#Peering_Response) otherwise.
* checking that the requester salt matches its hash chain by:
    * taking the difference between the timestamp of the peering request and the time the initial salt was set, and then dividing this number by `salt_update_interval`, rounding down;
    * hashing the requester public salt as many times as the number of salt changes;
    * finally, if the result does not match the initial salt, discard the peering request;
* applying a statistical test to the request defined as *d(remoteID, ownID, ζ_remote) < θ* for a fixed threshold θ, and discard the packet otherwise;
* accept the peering request by sending back a *positive* [Peering Response](#Peering_Response) if either one of the following conditions is satisfied, and send back a *negative* [Peering Response](#Peering_Response) otherwise:
    * the current size of the accepted neighbors list is smaller than *k/2*; 
    * the score defined as *s(ownID, remoteID, ζ_private)* is smaller than the current furtherest accepeted neighbor  (i.e., the neighbor with highest score). In this case, send a [Peering Drop](#Peering_Drop) packet to drop the furtherest accepeted neighbor replaced by the requester peer. 

## 2.2.3.4 Neighbor Removal

Neighbor removal can occur for several reasons:
* A node is replacing a neighbor with a better (in terms of score function) one;
* From the gossip layer, the connection with a neighbor is lost;
* If some form of reputation or bad behavior is being monitored, a neighbor could be dropped in case of misbehavior.

Indepenently from the reason, when a peer drops a neighbor *shall* send a [Peering Drop](#Peering_Drop) packet and remove the neighbor from its chosen/accepted neighbor list. Upon reception of a [Peering Drop](#Peering_Drop) packet, the peer *shall* remove the dropping neighbor from its chosen/accepted neighbor list.

## 2.2.3.5 Mana rank
Each peer discovered and verified via the *Peer Discovery* protocol *shall* have a mana value associated to it. The peer running the *Neighbor Selection* protocol *shall* keep this information up-to-date and use it to update a data structure called `manaRank` containing the list of the nodes' identities for each mana value. The aim of this ranking is to select a subset of peers having a similar mana to the node performing the ranking. More specifically, let's define `potential_neighbors` to be such a subset, that is divided into a `lower` and an `upper` set with respect to a `targetMana` value (i.e., the mana value of the node performing the ranking). By iterating over the `manaRank`, each node *shall* fill both the `lower` and  `upper` sets with nodes' identities having a similar rank to itself, not less/greater than a given threshold `rho` respectively and of, at least, size `R`.

The following pseudocode descibes a reference implementation of this process/
```
Inputs: 
    manaRank: mapping between mana values and the list of nodes' identities with that mana; 
    targetMana: the mana value of the node performing the ranking;
    rho: the ratio determining the lenght of the rank to consider;
    R: the minimum number of nodes' identities to return for both lower and upper sets;
    largest(R, targetMana): the set of R largest mana holders less than targetMana;
    smallest(R, targetMana): the set of R smallest mana holders greater than targetMana;

Outputs:
    potential_neighbors: the set of nodes' identities to consider for neighbor selection;

foreach <mana, identities> ∈ manaRank do
    if mana > targetMana then
        if mana / targetMana < rho then
            upperSet ← upperSet ∪ identities
    else if mana == 0 || mana == targetMana then
        break
    else if targetMana / mana < rho then
        lowerSet ← lowerSet ∪ identities

if len(lowerSet) < R then
	// set lowerSet with the R largest mana holders less than targetMana
	lowerSet ← largest(R, targetMana)
	
if len(upperSet) < R then
    // set upperSet with the R smallest mana holders greater than targetMana
	upperSet ← smallest(R, targetMana)

return potential_neighbors ← upperSet ∪ lowerSet

```

## 2.2.3.6 Packets

Each packet is encapsulated into a `data` field of a generic `Packet`. The `type` of the different packets *shall* be specified in the `type` field. Each packet *shall* be signed with the ed25519 private key of the sender's [identity](#Node_identities) and contain the related public key to allow the packet receiver to verify the signature. All the received packets *shall* be verified and those with invalid signature be discarded.

### Packet

<table>
     <tr>
         <th>Name</th>
         <th>Type</th>
         <th>Description</th>
     </tr>
     <tr>
         <td>type</td>
         <td>uint8</td>
         <td>Defines the type of the packet.</td>
     </tr>
     <tr>
         <td>data</td>
         <td>ByteArray</td>
         <td>contains the payload of the packet (e.g., a PeeringRequest packet).</td>
     </tr>
     <tr>
         <td>public_key</td>
         <td>ByteArray[32]</td>
         <td>The ed25519 public key of the peer's identity used to verify its signatures.</td>
     </tr>
     <tr>
         <td>signature</td>
         <td>ByteArray[32]</td>
         <td>The ed25519 signature of the `data` field, signed by using the private key of the peer's identity.</td>
     </tr>
 </table>

### Peering Request

<table>
     <tr>
         <th>Name</th>
         <th>Type</th>
         <th>Description</th>
     </tr>
     <tr>
         <td>timestamp</td>
         <td>time</td>
         <td>The unix timestamp of the PeeringRequest.</td>
     </tr>
     <tr>
         <td>salt</td>
         <td>ByteArray[20]</td>
         <td>The public salt of the requester.</td>
     </tr>
 </table>

### Peering Response

<table>
     <tr>
         <th>Name</th>
         <th>Type</th>
         <th>Description</th>
     </tr>
     <tr>
         <td>req_hash</td>
         <td>ByteArray[32]</td>
         <td>The blake2b digest of the corresponding received PeeringRequest packet.</td>
     </tr>
     <tr>
         <td>status</td>
         <td>bool</td>
         <td>The response (true or false) of the PeeringRequest.</td>
     </tr>
 </table>

### Peering Drop

<table>
     <tr>
         <th>Name</th>
         <th>Type</th>
         <th>Description</th>
     </tr>
     <tr>
         <td>timestamp</td>
         <td>time</td>
         <td>The unix timestamp of the drop.</td>
     </tr>
 </table>
